local embedding_size = 200;

{
   "train_data_path": "/fs/clip-psych/shing/umd_reddit_suicidewatch_dataset_v2/crowd/train/task_B_with_post.train",
   "validation_data_path": "/fs/clip-psych/shing/umd_reddit_suicidewatch_dataset_v2/crowd/test/task_B_with_post.test",
   //"test_data_path": "/fs/clip-psych/shing/umd_reddit_suicidewatch_dataset_v2/expert/task_B_with_post.expert",
   //"datasets_for_vocab_creation": ["train"],
   "dataset_reader": {
      "lazy": false,
      "type": "user_clpsych_feature_reader",
      "token_indexers": {
        "tokens": {
          "type": "single_id",
          "lowercase_tokens": true
        }
      }
   },
   "iterator": {
      "batch_size": 16,
      "type": "bucket",
      "sorting_keys": [["tokens", "list_list_num_tokens"]]
   },
   "model": {
       "type": "lr_glove_bow_empath_readability",
       "bow_embeddings": {
            "token_embedders": {
                "tokens": {
                    "type": "bag_of_word_counts",
                   "vocab_namespace": "tokens",
                   "ignore_oov": true
                }
            }
       },
       "word_embeddings": {
           "token_embedders": {
                "tokens": {
                    "type": "embedding",
                    "embedding_dim": embedding_size,
                    "trainable": false,
                    "pretrained_file": "(http://nlp.stanford.edu/data/glove.twitter.27B.zip)#glove.twitter.27B.200d.txt"
                }
            }
       },
       "word_to_sentence": {
           "type": "bag_of_embeddings",
           "embedding_dim": embedding_size,
           "averaged": false
       },
       "sentence_to_doc": {
           "type": "bag_of_embeddings",
           "embedding_dim": embedding_size,
           "averaged": false
       },
       "doc_to_user": {
           "type": "bag_of_embeddings",
           "embedding_dim": embedding_size,
           "averaged": true
       }
   },
   "trainer": {
        "validation_metric": "-loss",
        "num_epochs": 100,
        "optimizer": {
            "type": "adam",
            "lr": 0.003
        },
        "patience": 20,
        "cuda_device": -1
    },
    "vocabulary":{
      "min_count":{
        "tokens": 3
      }
    }
}