local hidden_size = 50;
local embedding_size = 768;

{
   "train_data_path": "/fs/clip-psych/shing/umd_reddit_suicidewatch_dataset_v2/crowd/train/postprocess_posts_full_train.jsonl",
   "validation_data_path" : "/fs/clip-psych/shing/umd_reddit_suicidewatch_dataset_v2/crowd/train/postprocess_posts_full_dev.jsonl",
   "test_data_path": "/fs/clip-psych/shing/umd_reddit_suicidewatch_dataset_v2/crowd/test/postprocess_posts_test_full.jsonl",
   "dataset_reader": {
      "lazy": false,
      "type": "user_clpsych_reader",
      "max_doc": 25,
      "token_indexers": {
          "bert": {
              "type": 'bert-pretrained',
              "pretrained_model": 'bert-base-uncased',
              "do_lowercase": true,
              "use_starting_offsets": true,
              "max_pieces": 128,
              "truncate_long_sequences": true
          }
      }
   },
   "iterator": {
      "batch_size": 1,
      "type": "bucket",
      "sorting_keys": [["tokens", "list_list_num_tokens"]]
   },
   "model": {
       "type": "3HAN_clpsych_pretrain",
       "word_embeddings": {
            "allow_unmatched_keys": true,
            "embedder_to_indexer_map": {
                "bert": ["bert", "bert-offsets"]
            },
            "token_embedders": {
                "bert": {
                    "type": "bert-pretrained",
                    "pretrained_model": 'bert-base-uncased',
                    "requires_grad": false
                }
            }
       },
       "word_to_sentence": {
           "type": "attention_rnn",
           "encoder":{
               "type": "gru",
               "input_size": embedding_size,
               "hidden_size": hidden_size,
               "bidirectional": true
           },
           "attention":{
               "type": "dot_product"
           }
       },
       "sentence_to_doc": {
           "type": "attention_rnn",
           "encoder":{
               "type": "gru",
               "input_size": hidden_size*2,
               "hidden_size": hidden_size,
               "bidirectional": true
           },
           "attention":{
               "type": "dot_product"
           }
       },
       "doc_to_user": {
           "type": "attention_rnn",
           "encoder":{
               "type": "gru",
               "input_size": hidden_size*2,
               "hidden_size": hidden_size,
               "bidirectional": true
           },
           "attention":{
               "type": "dot_product"
           }
       }
   },
   "trainer": {
        "num_epochs": 5,
        "optimizer": {
            "type": "adam",
            "lr": 0.003
        },
        "patience": 10,
        "cuda_device": [0,1]
    },
    "evaluate_on_test": true
}